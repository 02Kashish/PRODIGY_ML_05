{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJbW4mA35x82",
        "outputId": "93ccf9f1-e21b-433c-fa3c-c16edbeb75fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "101\n",
            "Train Data\n",
            "Found 7500 images belonging to 10 classes.\n",
            "\n",
            "Validation Data\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 344s 1s/step - loss: 1.0047 - accuracy: 0.7001 - val_loss: 0.6000 - val_accuracy: 0.8308\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 318s 1s/step - loss: 0.5028 - accuracy: 0.8621 - val_loss: 0.6160 - val_accuracy: 0.8160\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 339s 1s/step - loss: 0.3631 - accuracy: 0.9005 - val_loss: 0.4982 - val_accuracy: 0.8448\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 322s 1s/step - loss: 0.2819 - accuracy: 0.9249 - val_loss: 0.4887 - val_accuracy: 0.8676\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 321s 1s/step - loss: 0.2285 - accuracy: 0.9397 - val_loss: 0.4503 - val_accuracy: 0.8664\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 321s 1s/step - loss: 0.1941 - accuracy: 0.9485 - val_loss: 0.4580 - val_accuracy: 0.8668\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 320s 1s/step - loss: 0.1741 - accuracy: 0.9535 - val_loss: 0.4950 - val_accuracy: 0.8576\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 317s 1s/step - loss: 0.1432 - accuracy: 0.9672 - val_loss: 0.5118 - val_accuracy: 0.8708\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 316s 1s/step - loss: 0.1301 - accuracy: 0.9700 - val_loss: 0.4944 - val_accuracy: 0.8716\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 318s 1s/step - loss: 0.1148 - accuracy: 0.9748 - val_loss: 0.5033 - val_accuracy: 0.8664\n",
            "79/79 - 63s - loss: 0.4777 - accuracy: 0.8768 - 63s/epoch - 792ms/step\n",
            "\n",
            "Validation accuracy: 0.876800000667572\n",
            "\n",
            "Test accuracy: 0.876800000667572\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "with open(\"food-101/food-101/meta/classes.txt\", \"r\") as f:\n",
        "    CLASS_NAMES = [item.strip() for item in f]\n",
        "CLASS_NAMES = np.array(CLASS_NAMES)\n",
        "classes = CLASS_NAMES\n",
        "print(len(CLASS_NAMES))\n",
        "\n",
        "data_dir = 'food-101/food-101/images'\n",
        "data_dir = pathlib.Path(data_dir)#initialising necessary properties\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 299\n",
        "IMG_WIDTH = 299\n",
        "STEPS_PER_EPOCH = np.ceil(5000/BATCH_SIZE)\n",
        "\n",
        "#prepare train data generator with necessary augmentations and validation split\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        validation_split=0.25)\n",
        "\n",
        "\n",
        "\n",
        "#generate training data\n",
        "print('Train Data')\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    str(data_dir),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    classes = list(classes),\n",
        "    subset='training')\n",
        "\n",
        "#generate validation data\n",
        "print('\\nValidation Data')\n",
        "valid_data = train_datagen.flow_from_directory(\n",
        "    str(data_dir),\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes = list(classes),\n",
        "\n",
        "    subset='validation')\n",
        "\n",
        "\n",
        "\n",
        "mbv2 = Xception(weights='imagenet', include_top=False, input_shape = (299,299,3))\n",
        "x = mbv2.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "predictions = Dense(101,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=mbv2.input, outputs=predictions)\n",
        "model.compile(optimizer=SGD(lr=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_data, epochs=20, validation_data=valid_data)\n",
        "\n",
        "# Step 4: Evaluation\n",
        "test_loss, test_acc = model.evaluate(valid_data, verbose=2)\n",
        "print(\"\\nValidation accuracy:\", test_acc)\n",
        "print(\"\\nTest accuracy:\", test_acc)\n",
        "\n",
        "# Step 5: Deployment\n",
        "# Deploy the trained model in an application where users can upload images and receive predictions of food item labels and calorie content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSaGralm4svl",
        "outputId": "8aea8139-580a-4c6b-c8da-bdec32ef82db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "Predicted Class: beet_salad\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load a sample image for testing\n",
        "sample_image_path = 'path/to/sample.jpeg'\n",
        "img = image.load_img(sample_image_path, target_size=(299, 299))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Rescale the pixel values to [0, 1]\n",
        "\n",
        "# Use the trained model for prediction\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_index = np.argmax(predictions[0])\n",
        "\n",
        "class_labels = classes\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class_label}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
